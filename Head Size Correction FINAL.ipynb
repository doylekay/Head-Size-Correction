{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Statistical Adjustment of Volumetric MRI Data\n",
    "\n",
    "In this Jupyter notebook there are functions and explanations as to how to use each tool in the Head Size Correction package. Functions can be customized to fit individual research needs.\n",
    "\n",
    "This Jupyter notebook also serves as a tutorial tool for head size correction. This is intended to standardize methods used in volumetric estimation of subregions in longitudinal MRI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with importing numpy, matplotlib.pyplot, pandas, and various other packages to Python. Functions in these packages are embedded into the functions for the correction and for outlier detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_coef(x,y):\n",
    "    n = np.size(x)\n",
    "    m_x, m_y = np.mean(x), np.mean(y)\n",
    "    \n",
    "    SS_xy = np.sum(y*x) - n * m_y * m_x\n",
    "    SS_xx = np.sum(x*x) - n * m_x * m_x\n",
    "    \n",
    "    b_1 = SS_xy / SS_xx\n",
    "    b_0 = m_y - b_1 * m_x\n",
    "    \n",
    "    return b_0,b_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function returns the coefficients of linear regression. This coefficient will be embedded into various correction functions, regression functions, and residual functions. However, it may not be necessary to compute this value in your analysis, due to it being embedded in other functions. \n",
    "\n",
    "You can also use np.poly1d function to do the same thing, however this function is integrated in the rest of the functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction Methods \n",
    "\n",
    "The next two functions are various correction methods used for volumetric subregions. According to O'Brien et.al. 2011, there are 3 types of correction methods: proportional methods, ANCOVA methods, and residual methods. In this version of the software we use 2 types of methods, proportional and ANCOVA. There are two types of proportional methods used, one that is strictly the proportion of the ROI to the ICV, and one that is described in Liu 2014 that uses a power proportion method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ancova_volume(ICV, region):\n",
    "    mean_ICV = np.mean(ICV)\n",
    "    b = estimate_coef(ICV, region)\n",
    "    B = b[1]\n",
    "    adjusted_volume = region - B*(ICV - mean_ICV)\n",
    "    return adjusted_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function corrects a region based on headsize for ICV. It is according to the **insert citation here** method. *Insert Pros and Cons of this method?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion(ICV, region):\n",
    "    \n",
    "    proportion = region/ICV\n",
    "    \n",
    "    adjusted_volume = np.mean(ICV)*proportion\n",
    "    \n",
    "    return adjusted_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_proportion(ICV,region):\n",
    "    from scipy.optimize import curve_fit\n",
    "    def curve(x,a,b):\n",
    "        return a*x**b\n",
    "    \n",
    "    parameters, whatever = curve_fit(curve,ICV,region)\n",
    "    \n",
    "    a = parameters[0]\n",
    "    b = parameters[1]\n",
    "    \n",
    "    proportion = region/(ICV**b)\n",
    "    \n",
    "    adjusted_volume = np.mean(ICV**b) * proportion\n",
    "    \n",
    "    return adjusted_volume\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function corrects a region based on ICV based on the power-proportion method described in Liu 2014. The original method, the proportion method ... *pros and cons of this method*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual, Leverage, and Outlier Detection\n",
    "\n",
    "The next group of functions are in place to account for extreme values in the data. Best practice of science accounts for data that may cause too much influence in the analysis to be representative of the sample. These functions help to streamline the process of finding and dealing with outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_of_determination(x, y):\n",
    "    \n",
    "    b = estimate_coef(x,y)\n",
    "    \n",
    "    SS_tot_array = np.array([])\n",
    "    SS_res_array = np.array([])\n",
    "    \n",
    "    y_pred = b[0] + b[1] * x\n",
    "    for i in range(len(x)):\n",
    "        SS_tot_array = np.append(SS_tot_array, (y[i] - np.mean(y))**2)\n",
    "        SS_res_array = np.append(SS_res_array, (y[i] - y_pred[i])**2)\n",
    "    \n",
    "    SS_tot = np.sum(SS_tot_array)\n",
    "    SS_res = np.sum(SS_res_array)\n",
    "    \n",
    "    r_squared = 1 - (SS_res/SS_tot)\n",
    "        \n",
    "    return r_squared\n",
    "    \n",
    "def residual_list(x,y):\n",
    "    \n",
    "    b = estimate_coef(x,y)\n",
    "    \n",
    "    SS_tot_array = np.array([])\n",
    "    SS_res_array = np.array([])\n",
    "    \n",
    "    y_pred = b[0] + b[1] * x\n",
    "    for i in range(len(x)):\n",
    "        SS_tot_array = np.append(SS_tot_array, (y[i] - np.mean(y))**2)\n",
    "        SS_res_array = np.append(SS_res_array, (y[i] - y_pred[i])**2)\n",
    "    \n",
    "    SS_tot = np.sum(SS_tot_array)\n",
    "    SS_res = np.sum(SS_res_array)\n",
    "        \n",
    "    return SS_res_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leverage(region, ICV, method = \"residual/ancova\"):\n",
    "\n",
    "    if method == \"proportion\":\n",
    "        volume_adjusted = proportion(ICV, region)\n",
    "        \n",
    "    elif method == \"power proportion\":\n",
    "        volume_adjusted = power_proportion(ICV,region)\n",
    "    \n",
    "    else:\n",
    "        volume_adjusted = adjust_volume(region, region)\n",
    "        \n",
    "    h = np.array([])\n",
    "    for i in range(len(volume_adjusted)):\n",
    "        hi = (region[i] - volume_adjusted[i])/volume_adjusted[i]\n",
    "        h = np.append(h, hi)    \n",
    "        \n",
    "    return h\n",
    "\n",
    "def check_leverage(region: np.array, leverage:np.array) -> np.array:\n",
    "    n = len(region)\n",
    "    outliers = np.array([])\n",
    "    for i in leverage:\n",
    "        if i > 4/n:\n",
    "            outliers = np.append(outliers, i)\n",
    "            \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coef_of_determination function returns the coefficient of determination. This is useful in determining how well the data fits a linear curve. Once head size is corrected for, this value should be close to 0 as variation due to head size will have been taken out of the data.\n",
    "\n",
    "The residual_list function returns a numpy array of residuals in the data. \n",
    "\n",
    "The leverage function returns a numpy array of leverages in the data.\n",
    "\n",
    "The check_leverage function returns a numpy array of extreme leverages in the data. This uses a threshold of 1/(4n) as a high value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Leverage and Influential Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_leverage(icv):\n",
    "    ICV = np.array(icv)\n",
    "    ones = np.ones_like(ICV)\n",
    "    \n",
    "    data = np.vstack((ones, ICV))\n",
    "    data_matrix_T = np.matrix(data)\n",
    "    X = data_matrix_T.T\n",
    "    \n",
    "    H = X * (X.T * X) ** (-1) * X.T\n",
    "    x = np.diag(H)\n",
    "    h = 2/len(x)\n",
    "    \n",
    "    high_leverage = np.array([])\n",
    "    for i in x:\n",
    "        if i > (3 * h):\n",
    "            high_leverage = np.append(high_leverage, i)\n",
    "    \n",
    "    locations = np.array([])\n",
    "    for i in range(len(high_leverage)):\n",
    "        j = int(i)\n",
    "        location = np.where(x == high_leverage[j])\n",
    "        locations = np.append(locations, location)\n",
    "        \n",
    "    return high_leverage, locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW TO DO COOK'S DISTANCE FOR INFLUENTIAL POINTS\n",
    "'''\n",
    "m = smf.ols(formula = \"ICV ~ Cbl\",data = df).fit()\n",
    "infl = m.get_influence()\n",
    "sm_fr = infl.summary_frame()\n",
    "cooks_distance = sm_fr[\"cooks_d\"]\n",
    "'''\n",
    "\n",
    "def high_cooks_values(cooks_distance):\n",
    "    outliers = np.array([])\n",
    "    locations = np.array([])\n",
    "    for i in cooks_distance:\n",
    "        if i > 4/len(cooks_distance): # this can be changed to some other threshold \n",
    "            outliers = np.append(outliers, i)\n",
    "            \n",
    "    for i in range(len(outliers)):\n",
    "        j = int(i)\n",
    "        location = np.where(cooks_distance == outliers[j])\n",
    "        locations = np.append(locations, location)\n",
    "        \n",
    "    return outliers, locations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_line(x, y):\n",
    "    b = estimate_coef(x,y)\n",
    "    plt.scatter(x, y, color = \"b\", marker = \"o\", s=30)\n",
    "    \n",
    "    y_pred = b[0] + b[1] * x\n",
    "    \n",
    "    plt.plot(x,y_pred, color = \"g\")\n",
    "    \n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    \n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering by Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_sex(sex, region):\n",
    "    female_region = np.array([])\n",
    "    male_region = np.array([])\n",
    "    for i in range(len(sex)):\n",
    "        if sex[i] == 'f':\n",
    "            female_region = np.append(female_region, region[i])\n",
    "        else:\n",
    "            male_region = np.append(male_region, region[i])\n",
    "            \n",
    "    return(female_region, male_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hbp_filter(hbp, region):\n",
    "    yes_region = np.array([])\n",
    "    no_region = np.array([])\n",
    "    for i in range(len(sex)):\n",
    "        if hbp[i] == 0:\n",
    "            no_region = np.append(no_region, region[i])\n",
    "        else:\n",
    "            yes_region = np.append(yes_region, region[i])\n",
    "            \n",
    "    return(yes_region, no_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r'C:\\Users\\kayle\\Dropbox\\PA 2019-2020\\Raz_Study10_Raw-Manual-Volumes_for_ICV_adjust.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correction(data, region_s, ICV_s, method = \"ancova\", leverage_check = True):\n",
    "    region = data[region_s]\n",
    "    ICV = data[ICV_s]\n",
    "    \n",
    "    \n",
    "    ## leverage check\n",
    "    if leverage_check == True:\n",
    "        \n",
    "        formula_string = ICV_s +\"~\"+ region_s\n",
    "        \n",
    "        m = smf.ols(formula = formula_string, data = df).fit()\n",
    "        infl = m.get_influence()\n",
    "        sm_fr = infl.summary_frame()\n",
    "        cooks_distance = sm_fr[\"cooks_d\"]\n",
    "        \n",
    "        cooks_outliers = high_cooks_values(cooks_distance)\n",
    "        if len(cooks_outliers[0]) == 0:\n",
    "            print(cooks_outliers[1])\n",
    "            for j in cooks_outliers[1]:\n",
    "                data = data.drop()\n",
    "        else: \n",
    "            print(cooks_outliers)\n",
    "            \n",
    "        \n",
    "    ## correction step\n",
    "    if method == \"ancova\":\n",
    "         volume_adjusted = ancova_volume(ICV, region)\n",
    "    \n",
    "    elif method == \"proportion\":\n",
    "            volume_adjusted = proportion(ICV, region)\n",
    "            \n",
    "    elif method == \"power_proportion\":\n",
    "        volume_adjusted = power_proportion(ICV, region)\n",
    "            \n",
    "\n",
    "        \n",
    "    return(volume_adjusted)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
